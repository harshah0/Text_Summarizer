{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "mH7zrfEcdvRP",
        "outputId": "060a7ba0-d565-404f-ea8b-5725ca7f5d3b"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import re\n",
        "import heapq\n",
        "\n",
        "# Download required NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "\n",
        "# Input: Long text\n",
        "print(\"Enter a long paragraph or article (end with ENTER):\")\n",
        "input_text = input()\n",
        "\n",
        "if input_text.strip() == \"\":\n",
        "    print(\"\\n Please enter some text.\")\n",
        "else:\n",
        "    # Step 1: Clean text\n",
        "    text = re.sub(r'\\s+', ' ', input_text)\n",
        "    clean_text = re.sub(r'[^a-zA-Z]', ' ', text).lower()\n",
        "\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = word_tokenize(clean_text)\n",
        "\n",
        "    # Step 2: Create frequency table\n",
        "    word_frequencies = {}\n",
        "    for word in words:\n",
        "        if word not in stop_words:\n",
        "            word_frequencies[word] = word_frequencies.get(word, 0) + 1\n",
        "\n",
        "    # Step 3: Normalize frequencies\n",
        "    max_freq = max(word_frequencies.values())\n",
        "    for word in word_frequencies:\n",
        "        word_frequencies[word] /= max_freq\n",
        "\n",
        "    # Step 4: Score sentences\n",
        "    sentences = sent_tokenize(text)\n",
        "    sentence_scores = {}\n",
        "    for sent in sentences:\n",
        "        for word in word_tokenize(sent.lower()):\n",
        "            if word in word_frequencies:\n",
        "                if len(sent.split(' ')) < 30:\n",
        "                    sentence_scores[sent] = sentence_scores.get(sent, 0) + word_frequencies[word]\n",
        "\n",
        "    # Step 5: Select top sentences\n",
        "    summary_sentences = heapq.nlargest(3, sentence_scores, key=sentence_scores.get)\n",
        "    summary = ' '.join(summary_sentences)\n",
        "\n",
        "    # Output summary\n",
        "    print(\"\\n Summary:\\n\")\n",
        "    print(summary)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
